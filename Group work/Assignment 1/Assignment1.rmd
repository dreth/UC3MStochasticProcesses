---
title: 'Assignment 1'
author: "Group 1"
date: "November 22th, 2020"
output: 'pdf_document'
---

Importing libraries

```{r, echo=TRUE, warning=FALSE}
library(markovchain)
library(matlib)
```

Functions to solve the problems

```{r, echo=TRUE, warning=FALSE}
matrixpower <- function(M,k) {
  if(dim(M)[1]!=dim(M)[2]) return(print("Error: matrix M is not square"))
  if (k == 0) return(diag(dim(M)[1])) 
  if (k == 1) return(M)
  if (k > 1)  return(M %*% matrixpower(M, k-1))
}
```

# Problem 1

## a)

Markov chain criteria:

1- The probability of being in a state only depends on the previous state.

2- It's a stochastic process.

$X$ = The chain hits state $j$ at time $n$

$X_{n}$ is the scenario at time $n$

All states have finite expected return times and are communicated with each other, also the MC is irreducible, therefore its stationary distribution is **unique**.

![Graph for prob.1](./grafo1.png)

\newpage

## b)

We have first calculated the relative frequencies manually.

```{r, echo=TRUE, warning=FALSE}
load('PollutionMadrid.RData')
data <-  X[1,]
mat <- matrix(rep(0,36), nrow=6, byrow=T)
for (i in 1:length(data)) {
  if (data[i] == "Alert") {
    data[i] = 1
  } else if (data[i] == "NR") {
    data[i] = 2
  } else if (data[i] == "Sc1") {
    data[i] = 3
  } else if (data[i] == "Sc2") {
    data[i] = 4 
  } else if (data[i] == "Sc3") {
    data[i] = 5
  } else if (data[i] == "Sc4") {
    data[i] = 6
  }
}
data <- as.numeric(data)
for (i in 1:length(data)) {
  mat[data[i],data[i+1]] = mat[data[i],data[i+1]] + 1
}
mat[data[1460],data[1]] = mat[data[1460],data[1]] + 1

tbl <- table(data)
for (i in 1:length(tbl)) {
  mat[i,] = mat[i,]/tbl[i]
}
mat
```

\newpage

We then tested using the *markovchain* package in order to confirm our results.

```{r, echo=TRUE, warning=FALSE}
data <- X[1,]
markovchainFit(data)$estimate
```

&nbsp;

### What can you say of the comparison of your estimates andthe possible transitions between states that you had argued in part a

According to our probabilities shown in the graph. There are 3 arrows with probability 0. This is due to the fact that in the data there are zero transitions from $Sc2 \rightarrow Alert$, $Sc4 \rightarrow Alert$, $NR \rightarrow Alert$, $Alert \rightarrow Alert$.

This is logical given that it is very unlikely to hit an alert state. Unlike the rest of the states.

Later it will be shown that there's a unique stationary distribution (see 1d).

![Graph with probabilities for problem 1 (b)](./grafo1_probs.png)

\newpage

## c)

Given that the first state of the chain is NR. We see the following 7 states:

```{r, echo=TRUE, warning=FALSE}
data[1:7]
```

And we calculate the probability as follows:

```{r, echo=TRUE, warning=FALSE}
mat[2,2]^7
```

We can see the probability is 0.713843

## d)

We can see that because we have a unique solution to the system, we have a unique stationary distribution.

```{r, echo=TRUE, warning=FALSE}
stationary_dist <- function(P) {
    dim = sqrt(length(P))
    A = P - diag(dim)
    b = matrix(c(1,rep(0,dim-1)),nrow=dim,byrow=T)
    A[,1] <- rep(1,dim)
    print("The solution is the following:")
    return(matlib::Solve(t(A), b))
}
stat_dist <- stationary_dist(mat)
stat_dist
```

This is our stationary distribution:

$\pi_{1} = 0.00273973$

$\pi_{2} = 0.91780822$

$\pi_{3} = 0.04315068$

$\pi_{4} = 0.02123288$

$\pi_{5} = 0.00890411$

$\pi_{6} = 0.00616438$

\newpage

Comparing with the proportions we get from our data:

```{r, echo=TRUE, warning=FALSE}
rel_error = c()
props = table(data)/length(data)
results <- c(0.00273973,0.91780822,0.04315068,0.02123288,0.00890411,0.00616438)
for (i in 1:length(props)) {
    rel_error[i] <- abs(props[i]-results[i])/results[i]
}
```

We can see our relative errors are all quite low (<$1*10^{-5}$) 

## e)

Taking the 120th power of our transition matrix we get the following:

```{r, echo=TRUE, warning=FALSE}
matrixpower(mat,120)
```



\newpage

# Problem 2

## a)

We set up the following system of equations:

$\sum_{i=0} \pi_{i} P_{i,0}  = \pi_{1}$

$\sum_{i=1} \pi_{i} = 1$

$(1 - p) \pi_{1} = \pi_{2}$
$\dots$
$(1 - p) \pi_{n-2} = \pi_{n-1}$
$\dots$

For the first equation, each $P_{i,0} = p$, therefore:

$\sum_{i=0} P_{i,0} \pi_{i} = \pi_{1} \Rightarrow p \sum_{i=1} \pi_{i} = \pi_{1}$

$p = \pi_{1}$

$(1 - p)p = \pi_{2}$
$(1 - p)^{2} p = \pi_{3}$
$\dots$
$(1 - p)^{n-1} p = \pi_{n}$
$\dots$

Then, we get:




Because our MC is an irreducible infinite state MC, we have a unique stationary distribution $\pi$, $\pi_{i} = \frac{1}{\mu_{i}}$ and all states have expected finite return times then we have:

$E[T_{i}|X_{0} = i] = \mu_{i} = \frac{1}{\pi_{i}}$

## b)

Because it has a unique stationary distribution, it can only have one communication class (it is irreducible), all states are recurring states and there is no transient state.

## c)

```{r, echo=TRUE, warning=FALSE}
mc <- function(p, sequences ,steps) {
    n <- 100
    MarkovChain <- matrix(rep(0,sequences^2), nrow=sequences, byrow=TRUE)
    MarkovChain[,1] <- p
    for (i in 1:sequences) {
        if (i == sequences) {
            MarkovChain[i,i] <- 0
        } else {
            MarkovChain[i,i+1] <- 1-p
        }
    }
    return(MarkovChain)
}
```

