---
title: 'Stochastic Processes: Assignment 1'
author: "Group 1: Javier Esteban Aragoneses, Mauricio Marcos Fajgenbaun, Danyu Zhang, Daniel Alonso"
date: "November 27th, 2020"
output: 'pdf_document'
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  fig.path = "./figures/"
)
```

Importing libraries

```{r, echo=TRUE, warning=FALSE}
library(markovchain)
library(matlib)
```

Function to solve the problems

```{r, echo=TRUE, warning=FALSE}
# Thanks profe!
matrixpower <- function(M,k) {
  if(dim(M)[1]!=dim(M)[2]) return(print("Error: matrix M is not square"))
  if (k == 0) return(diag(dim(M)[1])) 
  if (k == 1) return(M)
  if (k > 1)  return(M %*% matrixpower(M, k-1))
}
```

# Problem 1

## a)

Markov chain criteria:

1- The probability of being in a state only depends on the previous state.

2- It's a stochastic process.

$X$ = The chain hits state $j$ at time $n$

$X_{n}$ is the scenario at time $n$

All states have finite expected return times and there is only a single communication class so the MC is irreducible, therefore its stationary distribution is **unique**.

![Graph for prob.1](./grafo1.png)

\newpage

## b)

We have first calculated the relative frequencies manually.

```{r, echo=TRUE, warning=FALSE}
# importing the data
load('PollutionMadrid.RData')
data <-  X[1,] # selecting the first line (as we are group 1)
mat <- matrix(rep(0,36), nrow=6, byrow=T) # creating an empty 6x6 matrix
# we substitute the characters with numbers for easier manipulation
for (i in 1:length(data)) {
  if (data[i] == "Alert") {
    data[i] = 1
  } else if (data[i] == "NR") {
    data[i] = 2
  } else if (data[i] == "Sc1") {
    data[i] = 3
  } else if (data[i] == "Sc2") {
    data[i] = 4 
  } else if (data[i] == "Sc3") {
    data[i] = 5
  } else if (data[i] == "Sc4") {
    data[i] = 6
  }
}

# Count transitions and add them to the matrix
data <- as.numeric(data)
for (i in 1:length(data)) {
  mat[data[i],data[i+1]] = mat[data[i],data[i+1]] + 1
}
# matrix wraps around so we count the last element > first element transition
mat[data[1460],data[1]] = mat[data[1460],data[1]] + 1

# Frequency table in order to create relative frequencies in transition matrix
tbl <- table(data)
for (i in 1:length(tbl)) {
  mat[i,] = mat[i,]/tbl[i]
}
mat
```

\newpage

We then tested using the *markovchain* package in order to confirm our results.

```{r, echo=TRUE, warning=FALSE}
data <- X[1,]
markovchainFit(data)$estimate
```

&nbsp;

### What can you say of the comparison of your estimates andthe possible transitions between states that you had argued in part a

According to our probabilities shown in the graph. There are 3 arrows with probability 0. This is due to the fact that in the data there are zero transitions from $Sc2 \rightarrow Alert$, $Sc4 \rightarrow Alert$, $NR \rightarrow Alert$, $Alert \rightarrow Alert$.

This is logical given that it is very unlikely to hit an alert state. Unlike the rest of the states.

Later it will be shown that there's a unique stationary distribution (see 1d).

![Graph with probabilities for problem 1 (b)](./grafo1_probs.png)

\newpage

## c)

Given that the first state of the chain is NR. We see the following 7 states:

```{r, echo=TRUE, warning=FALSE}
data[1:7]
```

And we calculate the probability as follows:

```{r, echo=TRUE, warning=FALSE}
mat[2,2]^7
```

We can see the probability is 0.713843

## d)

We can see that because we have a unique solution to the system, we have a unique stationary distribution.

```{r, echo=TRUE, warning=FALSE}
# function to calculate stationary distribution of a transition matrix
stationary_dist <- function(P) {
    dim = sqrt(length(P))
    A = P - diag(dim)
    b = matrix(c(1,rep(0,dim-1)),nrow=dim,byrow=T)
    A[,1] <- rep(1,dim)
    print("The solution is the following:")
    return(matlib::Solve(t(A), b))
}
stat_dist <- stationary_dist(mat)
stat_dist
```

Which yields the following stationary distribution:

$\pi_{1} = 0.00273973$

$\pi_{2} = 0.91780822$

$\pi_{3} = 0.04315068$

$\pi_{4} = 0.02123288$

$\pi_{5} = 0.00890411$

$\pi_{6} = 0.00616438$

\newpage

Comparing with the proportions we get from our data:

```{r, echo=TRUE, warning=FALSE}
rel_error = c()
props = table(data)/length(data)
results <- c(0.00273973,0.91780822,0.04315068,0.02123288,0.00890411,0.00616438)
for (i in 1:length(props)) {
    rel_error[i] <- abs(props[i]-results[i])/results[i]
}
rel_error
```

We can see our relative errors are all quite low (<$1*10^{-5}$) so we could say that the difference between both estimations is nearly negligible. 

## e)

### Proof that this MC has a limiting distribution

We have previously proven that this MC is irreducible. Now we want to prove that this MC is also aperiodic.

We can easily prove this by checking the paths from NR to the nodes it's connected with:

1st path: 3 steps: $NR \rightarrow Sc1 \rightarrow Sc2 \rightarrow NR)$

2nd path: 2 steps: $NR \rightarrow Sc1 \rightarrow NR)$

$\dots$

Because the $\{3,2,...\}$ and 2 elements of this set are prime numbers, the greatest common divisor of this set is always going to be 1.

This applies for all the other nodes as they all belong to the same class.

Therefore this chain has a **unique** stationary distribution which coincides with its limiting distribution.

### What does this mean, in terms of pollution episodes?

The proportion of pollution episodes depends on our limiting distribution, i.e. the long run proportion of pollution episodes with Scenario 1 will be the value of Sc1 in our limiting distribution. If we look ahead in the future, and we want to know the probability of being in a specific pollution episode scenario, $p_{ij}$ is the probability of being in scenario $j$.

Taking the a high power of our transition matrix we get the following limiting distribution:

```{r, echo=TRUE, warning=FALSE}
mp <- matrixpower(mat,120)
mp
```

\newpage

## f)

If we take the sum of the probability of scenarios 3, 4 and Alert: $P(Sc3) + P(Sc4) + P(Alert)$ multiplied by the amount of days in a year, we get the amount of days in a year with such driving restriction:

```{r, echo=TRUE, warning=FALSE}
365*(mp[1,1]+mp[1,5]+mp[1,6])
```

We get that the amount of days where driving is forbidden is 6.5 days. Approximately a week.

\newpage

# Problem 2

## a)

We set up the following system of equations:

$\begin{cases}
\sum_{i \in \mathbb{N} \cup \{0\}} \pi_{i} P_{i,0}  = \pi_{1} \\
\sum_{i \in \mathbb{N} \cup \{0\}} \pi_{i} = 1 \\
(1 - p) \pi_{1} = \pi_{2} \\
\dots \\
(1 - p) \pi_{n-2} = \pi_{n-1} \\
\dots \\
\end{cases}$


For the first equation, each $P_{i,0} = p$, therefore:

$\sum_{i \in \mathbb{N} \cup \{0\}} P_{i,0} \pi_{i} = \pi_{1} \Rightarrow p \sum_{i \in \mathbb{N} \cup \{0\}} \pi_{i} = \pi_{1}$

And we get: 

$p = \pi_{1}$

For the rest of the equations we have the following:

$(1 - p)p = \pi_{2}, (1 - p)^{2} p = \pi_{3}, \dots, (1 - p)^{n-1} p = \pi_{n}, \dots$

Then, we get the following result:

$p + (1-p)p + (1-p)^{2} p + \dots + (1-p)^{n-1} + \dots = \sum_{i \in \mathbb{N} \cup \{0\}} \pi_{i} = 1$

The left side of this equation can be summarized by a summation:

$p \sum_{i \in \mathbb{N} \cup \{0\}} (1-p)^{k} =  \sum_{i \in \mathbb{N} \cup \{0\}} \pi_{i} = 1$

The summation on the left hand side is a geometric series where $\langle{(1-p)} < 1$, therefore:

$p * \frac{1}{1 - (1 - p)} = 1$

This series confirms that $\pi P = \pi$ because:

$\begin{bmatrix} p & (1 - p)p & \dots & (1 - p)^{n} p & \dots \end{bmatrix}
\begin{bmatrix} p & 1-p & \dots 0 \\ \vdots & \vdots & \ddots \end{bmatrix}
= \pi$

Performing this matrix product we get:

$\begin{cases}
\pi_{1} = p \\
\pi_{2} = p (1-p) \\
\pi_{3} = p (1-p)^{2} \\
\dots \\
\pi_{n} = p (1-p)^{n-1} \\
\dots
\end{cases}$

Which is the stationary distribution of the chain.

Because our MC is an irreducible infinite state MC, we have a unique stationary distribution $\pi$, $\pi_{i} = \frac{1}{\mu_{i}}$ and not all states have expected finite return times then we have:

$E[T_{i}|X_{0} = i] = \mu_{i} = \frac{1}{\pi_{i}}$

\newpage

## b)

As it is aperiodic and irreducible markov chain, it has a limiting distribution.

## c)

We define the following function to simulate $n$ steps with initial value $p$.

```{r, echo=TRUE, warning=FALSE}
sim <-function(x0,n,p){ 
    n <- n-2
    x = rep(0,n)
    for (i in 1:n) {
        u=runif(1) 
        if (u <= p) {
            x[i+1] = x[i] + 1
        } else {
            x[i+1] = 0
        }
    } 
    return(c(x0,x))
}
```

&nbsp;

We simulate $n=30$ steps to test the function with initial value $x_{0} = 100$ and $p=0.95$:

```{r, echo=TRUE, warning=FALSE}
sim(100,30,0.95)
```

## d)

We generate 8 trajectories of length 1000 with different intiial values between [100,1000]

```{r, echo=TRUE, warning=FALSE, results='hide'}
# simulating trajectories
initial_x = sample((100:1000), 8)
trajs = matrix(rep(0,8*1000),nrow=1000,byrow=T)
for (i in 1:8) {
    trajs[,i] <- sim(initial_x[i], 1000, 1/2)
}
```

```{r, echo=TRUE, warning=FALSE}
# plotting trajectories
par(mfrow=c(4,2), mar=c(1,1,1,1))
for (i in 1:8) {
    plot(trajs[,i], ylim=c(0,1001))
}
```

The limiting distribution of this chain does not really depend at all on the first value. As such initial value could be a high number (between 100-1000), given that the probability corresponding to our group number ($k=1$) produces a very high $p=\frac{1}{1+k} = \frac{1}{2}$, therefore the chain drops very quickly to 0 and remains there without climbing values very much.

Our maximums per simulation are always the initial value:

```{r, echo=TRUE, warning=FALSE}
maximums = c()
for (i in 1:8) {
    maximums[i] = max(trajs[,i])
}
maximums
```

While the second highest values will be the followings:

```{r, echo=TRUE, warning=FALSE}
maximums = c()
for (i in 1:8) {
    maximums[i] = max(trajs[,i][2:1000])
}
maximums
```

Which are all significantly lower than our initial values.